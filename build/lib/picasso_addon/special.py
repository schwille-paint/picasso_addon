# Import modules
import numpy as np
import pandas as pd
import importlib
  
#%%
def combine_picks(locs,info_locs,props,N,compress=False):
    """ 
    Combines N picks of picasso '_picked' file into single pick.
        1) Standardized filter (using quantiles on distributions) is applied to corresponding '_picked_props' file.
           Just remaining picks will be combined.
        2) Combined groups are saved with extension '_picked_stackN' and meta with paramters is saved in yaml keeping original yaml information from '_picked' file. 
    
    Parameters
    ---------
    path_locs : str
        Path to '_picked' file
    path_props : str
        Path to '_picked_props' file
    N: int
        N picks will be combined into single pick
    compress: bool
        If true all photon values of '_picked' file will be set to mean photon value to avoid addition of noise, that may affect autocorrelation 
    Returns
    -------
    locs_combine: pandas.DataFrame
        

    """
    ############################################################# Definitions and modules
    from tqdm import tqdm
    
    def map_groups(df,group_map):
        isin=(group_map[:,0]==df.group.unique())#.any()
    
        try: 
            df.loc[:,'group']=group_map[isin,1]
        except ValueError:
            df.loc[:,'group']=0
        
        return df
    ############################################################# Compression
    #### Bring all localizations to same photon level to avoid addition of noise
    if compress:
        locs.loc[:,'photons']=locs.photons.mean()
   
    ############################################################# Combine remaining groups in '_picked'
    print('Combining groups into stacks of %i...'%(N))
    #### Get groups
    groups=props.group.unique()
    groupsL=len(groups)
    #### Combined group IDs
    combinedN=np.floor(groupsL/N).astype(int) # Number of combined groups
    combined=np.array([[i]*N for i in range(1,combinedN+1)]).flatten() # Combined group IDs
    #### Map original to combined groups
    groups_map=np.zeros([groupsL,2])
    groups_map[:,0]=groups
    groups_map[0:combinedN*N,1]=combined
    #### Remove remaining groups that do not fit in combined groups (zero entries)
    groups_map=groups_map[groups_map[:,1]>0,:] 
    #### Combine groups
    tqdm.pandas()
    locs_combine=locs.groupby('group').progress_apply(lambda df: map_groups(df,groups_map))
    #### Remove group=0 (filtered out) from locs_combine
    locs_combine.drop(locs_combine[locs_combine.group==0].index,inplace=True)
    
    ############################################################# Save files
    print('Saving ...')
    info_combine=info_locs
    ADDdict={'Generated by':'pickprops_calls.combine_picks.py',
             'N': N,
             'compress':compress}
    info_combine.extend([ADDdict])
  
    return locs_combine,info_combine
    
    
#%%
def segment_time(path,noFrames_seg):
    
    #### Load modules
    import lbfcs.var_io as var_io
    importlib.reload(var_io)
    
    #### Load locs and yaml
    locs,meta=var_io.read_locs(path)
    noFrames=meta[0]['Frames'] # Number of frames in locs
    #### Define time segments
    noSegments=np.floor(noFrames/noFrames_seg).astype(int) # no. of segments
    start_frame=[i*noFrames_seg for i in range(0,noSegments)] # start frames of new segments
    end_frame=[i*noFrames_seg for i in range(1,noSegments+1)] # end frames of new segment
    #### Assign noFrames_new to meta_seg for saving
    meta_seg=meta
    meta_seg[0]['Frames']=noFrames_seg
    
    #### Split locs file according to time segments
    for i in range(0,noSegments):
        print('_%i_of_%i'%(i+1,noSegments))
        #### Split locs
        locs_seg=locs.loc[(locs.frame>=start_frame[i])&(locs.frame<end_frame[i])]
        #### Substract start_frame
        locs_seg.loc[:,'frame']=locs_seg.loc[:,'frame'].values-start_frame[i]
        var_io.save_locs(locs_seg,meta_seg,path,savename_ext='_%i_of_%i'%(i+1,noSegments))
        
    return 

#%%
def tile_locs(path,noTiles,center,width):
    """ 
    Assigns group index to quadratic ROIs (tiles) of picasso _locs file. 
        1) locs are cropped to region of width 'width' in both x&y direction centered around 'center'
        2) Cropped region is split into tiles. Number of tiles is given by square of 'noTiles'.
        3) group index will be assigned to locs file according to tiles and locs_picked is returned and saved.
            -> For noTiles=2 indexing looks like this
            ______________
            |      |     |
            |  2   |  3  |
            |______|_____|
            |      |     |
            |  0   |  1  |
            |______|_____|
        4) Tiled file is saved with extension '_picked_tile' and meta with containing paramters is saved in yaml keeping original yaml information
            
    Parameters
    ---------
    path : str
        Path to _locs file
    NoTiles : int
        Number of tiles (in one dimension)
    center: list
        [x,y] in px as center for cropped region
    width: float
        Full width of cropped region
    
    Returns
    -------
    locs_picked : pandas.DataFrame
        Cropped _locs file with group index assigned according to tiles

    """
    
    #### Load modules
    import lbfcs.var_io as var_io
    importlib.reload(var_io)
    
    #### Load locs and yaml
    locs,meta=var_io.read_locs(path)
       
    #### Restrict locs to centered 512x512px ROI
    istrue_x=np.absolute(locs.x-center[0])>width/2
    istrue_y=np.absolute(locs.y-center[1])>width/2
    istrue_xy=istrue_x|istrue_y
    locs.drop(locs[istrue_xy].index,inplace=True)
    #### Substract boarder x-y values
    locs.loc[:,'x']=locs.loc[:,'x']-(center[0]-width/2)
    locs.loc[:,'y']=locs.loc[:,'y']-(center[1]-width/2)
    #### Define tiles
    tile_width=width/noTiles
    #### x-column ranges
    low_x=np.array([i*tile_width for i in range(0,noTiles)])
    up_x=np.array([i*tile_width for i in range(1,noTiles+1)])
    #### y-row ranges
    low_y=np.array([i*tile_width for i in range(0,noTiles)])
    up_y=np.array([i*tile_width for i in range(1,noTiles+1)])  
    #### Assing group index according to tiles
    group_index=0
    for j in range(0,noTiles): # loop through y-row
        istrue_y=(locs.y>low_y[j])&(locs.y<up_y[j])
        for i in range(0,noTiles): # loop through x-row
            print('Tile %i'%(group_index))
            istrue_x=(locs.x>low_x[i])&(locs.x<up_x[i])
            #### Intersection of x&y-stripe gives tile
            istrue_tile=istrue_x&istrue_y
            #### Assign group index to tile
            locs.loc[istrue_tile,'group']=group_index
            #### Raise group index by one for next tile
            group_index+=1
            
     #### Save file
    meta_tile=meta
    ADDdict={'Generated by':'pickprops_calls.tile_locs.py',
             'center of ROI':center,
             'full width of ROI':width,
             'number of tiles per row-column':noTiles}
    meta_tile.extend([ADDdict])
    var_io.save_locs(locs,meta_tile,path,savename_ext='_picked_tile')   
            
    return locs

#%%
def props_add_nn(df):
    """ 
    Adds nearest neighbouring group to _props file and saves it with file extension '_nn' 
           
    Parameters
    ---------
    df : pandas.DataFrame
        _props DataFrame as generated by modules/pickprops.py from picasso locs_picked file
    
    Returns
    -------
    loc_props : pandas.DataFrame
        Original DataFrame as in 'path' but with nearest neigbour distance (px) as column 'nn'.

    """
    
    #### Load modules
    from tqdm import tqdm
    
    #### Function definitions 
    #### Calculate minimal radial distance of group to all neigbours
    def get_nn(df,x,y,group_ids):
        #### Coordinates and id of reference group
        x0=df.mean_x.values # x-coordinate
        y0=df.mean_y.values # y coordinate
        
        #### Get nearest neighbour
        r=np.sqrt((x-x0)**2+(y-y0)**2) # Radial distance
        nn_index=np.argmin(r[r>0]) # Get minimum except distance to itself
        nn=group_ids[r>0][nn_index] # id of neareast neighbour
        nn_r=r[r>0][nn_index]
        
        #### Assign to output
        df['nn']=nn
        df['nn_r']=nn_r
        return df
    
    #### reset index to get 'group' column
    df.reset_index(inplace=True)
    #### Get coordinates of all groups in df and ids
    x=df.mean_x.values
    y=df.mean_y.values
    group_ids=df.group.values
    #### Apply get_nn
    tqdm.pandas() # For progressbar under apply
    df_nn=df.groupby('group').progress_apply(lambda df: get_nn(df,x,y,group_ids))
        
    return df_nn

#%%
def lineup(locs,info):
    """ 
    Redistributes picks along line and adjusts information in info_locs accordingly.
           
    Parameters
    ---------
    locs : pandas.DataFrame
        _picked.hdf5 as generated by picasso.render and loaded as pandas.DataFrame
    info : list of dicts
        _picked.yaml as generated by picasso.render and loaded as list of dicts
    
    Returns
    -------
    locs_lineup : pandas.DataFrame
        Redistributed _picked along line :
            1) Median y-coordinate of pick centered on pick-diameter/2 as given in info_locs
            2) Median x-coordinate of pick shifted by pick diamter to right pick after pick
    info_lineup: list of dicts
            Same as info_locs but 'Height' changed to pick_diameter and 'Width' changed to (#picks x pick_diameter)
    """
    
    ############################################################## Center picks   
    locs_lineup=locs.copy()
    info_lineup=info.copy()
    
    orig_pick_diameter=info[-1]['Pick Diameter'] # Load original pick diameter for centering
    
    center_x=locs.groupby('group').apply(lambda df: df.x-df.x.median()).values
    center_y=locs.groupby('group').apply(lambda df: df.y-df.y.median()).values
    
    locs_lineup.y=center_y+orig_pick_diameter/2
    locs_lineup.x=center_x+orig_pick_diameter/2
    
    info_lineup[0]['Width']=orig_pick_diameter
    info_lineup[0]['Height']=orig_pick_diameter
    
    ############################################################## Redistribute picks along line
    group_len=locs.groupby('group').size().values # Number of locs in group
    group_center_x=np.arange(0,len(group_len)*orig_pick_diameter,orig_pick_diameter) # x-shift per group
    
    ### Create vector of shifts for all localizations
    dx=[]
    for i in range(0,len(group_len)): dx+=[group_center_x[i]]*group_len[i]
    dx=np.array(dx)
    ### Shift localizations by dx
    locs_lineup.x+=dx
    ### Change info to new width
    info_lineup[0]['Width']=int(dx[-1]+orig_pick_diameter)
    
    return locs_lineup,info_lineup,group_center_x+orig_pick_diameter/2
    